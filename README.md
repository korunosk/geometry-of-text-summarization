# Geometry of Text Summarization

This is the official repository containing all the relevant code written for my semester project at Data Science lab.

The folder `src/` contains external Python code, obtained from other modules and instalation instructions are given in `instructions/`.

## Data

The data used for the analysis was obtained from TAC-2008 and TAC-2009. After simple preprocessing, we generated two JSON files, one per conference, that contain all the relevant textual data. You can find them in the `data/` folder in this repository.

For our models we need the training data shuffled. This caused problems when loading the topic data. To overcome the waiting time, we serialize each part of the topic's data on disk using the `main_split.py` script.

TODO: link to hosted embedded data

## Embeddings

Many of our methods require the data to be represented as numerical vectors. For this, we embedded the textual data from the datasets using four methods: LSA, GloVe, fasttex, and BERT. We have several scripts that produce the necessary dense vector representations. They are given below:
- LSA: use `main_encoding.py` - set `EMBEDDINGS_DIR`'s second argument to `LSA`
- GloVe: use `main_encoding.py` - set `EMBEDDINGS_DIR`'s second argument to `GloVe`
- fasttex: use `main_encoding.py` - set `EMBEDDINGS_DIR`'s second argument to `fasttext`
- BERT: `embeddings.ipynb` is a Google Colab notebook for producing BERT-sent and BERT-word embeddings

For BERT, you need to run the notebook in Google Colab and:
1. Upload config.py and helpers.py
2. Make the `data` directory
3. Upload TAC2008.json and TAC2009.json in `data`

Furthermore, the `encoders.py` script contains the actual functions for producing the embeddings for the different methods.

Only LSA embeddings were generated by us using the `main_lsa.py` script. All the others are pre-trained and downloaded from the internet.

## Baseline metrics

The implementation of the baseline metrics is given in `relevance.py` and `redundancy.py` scripts. To obtain the results for the baseline metrics, use the `main_experiments.py` script. The main experiment executor class is in `experiment_executors.py`. This class depends on [Ray](https://github.com/ray-project/ray), a framework for distributed applications.

## Models

We used PyTorch to generate our ML models. Their configuration parameters are given in `config_models.py`. Their definition and datasets are given in `models.py` and `datasets.py` respectively.

The `cross-validate.ipynb` and `stratified.ipynb` are two notebooks that train the models with two approaches. The former tests generalization while the latter tests the learning capacity.

Pretrained models are stored in `models_all.zip` and `models_stratified.zip`.
